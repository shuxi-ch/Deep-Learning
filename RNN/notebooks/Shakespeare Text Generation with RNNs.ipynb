{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y-8fgHBjT25m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Bidirectional, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LambdaCallback\n",
        "from tokenizers import ByteLevelBPETokenizer # Using Hugging Face's tokenizers\n",
        "import numpy as np\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import heapq # For Beam Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhdKENzUBFh"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oGXKhU7pT-AW"
      },
      "outputs": [],
      "source": [
        "# Data parameters\n",
        "DATA_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        "DATA_PATH = 'shakespeare.txt'\n",
        "TOKENIZER_PATH = 'tokenizer_models/shakespeare_bpe_tokenizer'\n",
        "VOCAB_SIZE = 10000 # Desired vocabulary size for BPE\n",
        "\n",
        "# Model parameters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 512\n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LENGTH = 50 # Length of input sequences\n",
        "BIDIRECTIONAL = True # Use bidirectional layers?\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "GRADIENT_CLIP_NORM = 1.0 # Norm for gradient clipping\n",
        "OPTIMIZER_TYPE = 'adam' # 'adam' or 'rmsprop'\n",
        "VALIDATION_SPLIT = 0.1 # Use 10% of data for validation\n",
        "\n",
        "# Generation parameters\n",
        "GENERATION_LENGTH = 500\n",
        "START_STRING = u\"ROMEO:\" # Seed text for generation\n",
        "TEMPERATURES = [0.2, 0.5, 1.0, 1.2] # Different temperatures for sampling\n",
        "BEAM_WIDTH = 3 # Beam width for beam search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaKaIiLCUDV5"
      },
      "source": [
        "### Data Preprocessing\n",
        "1. tokenizer: Afer downloading the data, here I used Byte-Level Byte Pair Encoding (BPE) because out-of-vocabulary (OOV) words and creates huge vocabularies, and character tokenization often results in very long sequences for the RNN to process. \n",
        "   *   **Subword Approach:** BPE learns common sequences of characters (subwords) directly from the data. It starts with individual bytes and iteratively merges the most frequent adjacent pairs. This creates a vocabulary that includes common words, word fragments, and characters.\n",
        "   *   **Handles OOV:** Unknown words can often be represented as a sequence of known subwords, making it more robust than assigning a single `<UNK>` token.\n",
        "   *   **Vocabulary Control:** to balance vocabulary richness and model complexity.\n",
        "   *   **Byte-Level:** It operates on bytes, meaning it can handle any text without encountering unknown characters.\n",
        "   Note: **Hugging Face `tokenizers` library** it's highly optimized (written in Rust), widely used, and makes implementing complex tokenizers like BPE straightforward.\n",
        "\n",
        "2. Loading the Consistent Tokenizer\n",
        "   Specify the `<PAD>` token and its ID to make the tokenizer object ready for use in padding sequences during data preparation.\n",
        "\n",
        "3. Gentle Text Cleaning\n",
        "   Before tokenizing, some light preprocessing were applied, including converting to lowercase, normalizing whitespace, removing any leading/trailing whitespace.\n",
        "\n",
        "4. Creating Training Sequences\n",
        "   Structure the flat list of token IDs into input/target pairs suitable for training an RNN on next-token prediction. Use a sliding window (SEQ_LENGTH) to create input sequences (X) and corresponding target sequences (y), where y is X shifted one token forward (y[t] = X[t+1]). Directly sets up the supervised learning task for language modeling and facilitates teacher forcing during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aweCzBGGUDdp"
      },
      "outputs": [],
      "source": [
        "def download_data(url, path):\n",
        "    \n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Downloading data from {url}...\")\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        with open(path, 'w', encoding='utf-8') as f:\n",
        "            f.write(response.text)\n",
        "        print(f\"Data downloaded and saved to {path}\")\n",
        "    else:\n",
        "        print(f\"Data file {path} already exists.\")\n",
        "\n",
        "def train_tokenizer(text_path, save_path, vocab_size):\n",
        "    \n",
        "    if not os.path.exists(f\"{save_path}-vocab.json\"):\n",
        "        print(\"Training BPE tokenizer...\")\n",
        "        tokenizer = ByteLevelBPETokenizer()\n",
        "        tokenizer.train(files=[text_path], vocab_size=vocab_size, min_frequency=2,\n",
        "                        special_tokens=[\"<PAD>\", \"<UNK>\", \"<BOS>\", \"<EOS>\"]) # Add special tokens if needed\n",
        "        # Create the directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        tokenizer.save_model(os.path.dirname(save_path), os.path.basename(save_path))\n",
        "        print(f\"Tokenizer trained and saved to {save_path}-vocab.json and {save_path}-merges.txt\")\n",
        "    else:\n",
        "        print(\"Tokenizer already trained.\")\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "    \"\"\"Loads a trained BPE tokenizer.\"\"\"\n",
        "    vocab_file = f\"{tokenizer_path}-vocab.json\"\n",
        "    merges_file = f\"{tokenizer_path}-merges.txt\"\n",
        "    if not os.path.exists(vocab_file) or not os.path.exists(merges_file):\n",
        "         raise FileNotFoundError(f\"Tokenizer files not found at {tokenizer_path}. Please train first.\")\n",
        "    print(f\"Loading tokenizer from {tokenizer_path}...\")\n",
        "    tokenizer = ByteLevelBPETokenizer(vocab_file, merges_file)\n",
        "    # Manually set padding if needed, ensure consistent ID\n",
        "    tokenizer.enable_padding(pad_id=tokenizer.token_to_id(\"<PAD>\") if \"<PAD>\" in tokenizer.get_vocab() else 0, pad_token=\"<PAD>\")\n",
        "    return tokenizer\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Basic text cleaning.\"\"\"\n",
        "    text = text.lower()\n",
        "    # Optional: Add more cleaning like removing stage directions if desired\n",
        "    # text = re.sub(r'\\[.*?\\]', '', text) # Example: remove text in brackets\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Normalize whitespace\n",
        "    return text\n",
        "\n",
        "def create_sequences(tokenized_ids, seq_length):\n",
        "    \"\"\"Creates input and target sequences.\"\"\"\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(tokenized_ids) - seq_length):\n",
        "        sequences.append(tokenized_ids[i:i + seq_length])\n",
        "        targets.append(tokenized_ids[i + 1:i + seq_length + 1]) # Target is sequence shifted by one\n",
        "    return np.array(sequences), np.array(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz0-fbDZUIxF"
      },
      "source": [
        "### Implement RNN Architectures\n",
        "\n",
        "1. Flexible RNN Architecture\n",
        "    This function builds a sequence prediction model using one of the following architectures:\n",
        "      - Simple RNN (Vanilla)\n",
        "      - GRU (Gated Recurrent Unit)\n",
        "      - LSTM (Long Short-Term Memory) — used by default.\n",
        "    These RNNs are designed to capture temporal dependencies in text, with GRUs and LSTMs offering better long-term memory retention compared to vanilla RNNs.\n",
        "2. Input Layer with Batch Size Control\n",
        "   - The input layer accepts sequences of fixed length (seq_length).\n",
        "   - If a GPU is available, the batch size can be explicitly specified (mainly useful for stateful RNNs during inference or streaming scenarios).\n",
        "   - By default, statefulness is disabled to simplify training and support variable batch sizes.\n",
        "3. Embedding Layer\n",
        "   - Transforms token IDs into dense vector representations (embedding_dim).\n",
        "   - Allows the model to learn semantic relationships between tokens.\n",
        "4. RNN Layer Selection\n",
        "   - Dynamically instantiates a SimpleRNN, GRU, or LSTM layer based on the rnn_type argument.\n",
        "   - return_sequences=True ensures the RNN outputs a hidden state at each timestep, essential for sequence-to-sequence prediction.\n",
        "   - Uses 'glorot_uniform' initializer for good weight distribution at the start.\n",
        "   - stateful=False by default for easier training across batches.\n",
        "5. Bidirectional Option\n",
        "   - If bidirectional=True, wraps the RNN layer with Bidirectional() to allow the model to learn from both past and future contexts.\n",
        "   - This effectively doubles the RNN’s output dimensionality (e.g., from rnn_units to 2*rnn_units if merge_mode='concat').\n",
        "   - The output is still compatible with the following Dense layer, which automatically adjusts.\n",
        "6. Output Layer\n",
        "   - A fully connected Dense layer with softmax activation outputs a probability distribution over the entire vocabulary for each timestep.\n",
        "   - This supports next-token prediction by assigning probabilities to each possible token.\n",
        "7. Modular Design\n",
        "   - Keeps training-time and generation-time considerations separate.\n",
        "   - If needed, a stateful inference version of the model can be constructed later for more fine-grained control (e.g., one-token-at-a-time generation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKlo8-pAUI4N"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size, seq_length, rnn_type='LSTM', bidirectional=False):\n",
        "    \"\"\"Builds the RNN model (Vanilla RNN, LSTM, or GRU).\"\"\"\n",
        "    print(f\"Building model: RNN Type={rnn_type}, Bidirectional={bidirectional}\")\n",
        "\n",
        "    inputs = Input(shape=(seq_length,), batch_size=batch_size if tf.config.list_physical_devices('GPU') else None) # Specify batch_size only for stateful on GPU if needed\n",
        "\n",
        "    embedding = Embedding(vocab_size, embedding_dim)(inputs)\n",
        "\n",
        "    rnn_layer_args = {'units': rnn_units,\n",
        "                      'return_sequences': True,\n",
        "                      'recurrent_initializer': 'glorot_uniform',\n",
        "                      #'stateful': True # Make stateful ONLY for specific inference scenarios, simpler without for training\n",
        "                      }\n",
        "\n",
        "    if rnn_type == 'SimpleRNN':\n",
        "        rnn_layer = SimpleRNN(**rnn_layer_args)\n",
        "    elif rnn_type == 'GRU':\n",
        "        rnn_layer = GRU(**rnn_layer_args)\n",
        "    else: # Default to LSTM\n",
        "        rnn_layer = LSTM(**rnn_layer_args)\n",
        "\n",
        "    if bidirectional:\n",
        "        # Bidirectional wrapper doubles the output units implicitly if merge_mode='concat' (default)\n",
        "        rnn_output = Bidirectional(rnn_layer)(embedding)\n",
        "        # Adjust dense layer input size if needed, but Dense adapts automatically\n",
        "    else:\n",
        "        rnn_output = rnn_layer(embedding)\n",
        "        # Output layer predicts the next token ID\n",
        "    outputs = Dense(vocab_size, activation='softmax')(rnn_output) # Use softmax for probability distribution\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Create a separate inference model structure if needed (especially for state management)\n",
        "    # For this setup, we can rebuild a stateful version or pass state manually during generation\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oVuFRzgUOdc"
      },
      "source": [
        "### Train and Optimize Models\n",
        "Two-step setup: compile the model with appropriate optimization strategies, and then launch training with robust monitoring mechanisms.\n",
        "\n",
        "- Model Compilation:\n",
        "    The model uses SparseCategoricalCrossentropy as the loss function, which is well-suited for multi-class classification where target labels are integer-encoded token IDs.It support both Adam and RMSprop optimizers—two popular choices for RNN training. Adam is generally more adaptive, while RMSprop can sometimes offer better stability in sequence tasks. Gradient clipping (clipnorm) is applied to prevent exploding gradients during backpropagation through time (BPTT), which is particularly important in RNNs.\n",
        "- Training Strategy:\n",
        "    The model is trained using model.fit() on the dataset and validated on a separate val_dataset. Two key callbacks are used:\n",
        "    - ModelCheckpoint: Automatically saves the best model weights (based on validation loss) to prevent overfitting and ensure recoverability.\n",
        "    - EarlyStopping: Monitors validation loss and stops training early if no improvement is observed for 3 consecutive epochs, while restoring the best-performing weights.\n",
        "- Teacher Forcing:\n",
        "    Teacher forcing is implicitly handled by the way training sequences are constructed—each input sequence is paired with its ground truth next-token sequence. No need for additional mechanisms like a forcing ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R6DQnFE5URd3"
      },
      "outputs": [],
      "source": [
        "def compile_model(model, optimizer_type, learning_rate, clip_norm):\n",
        "    \"\"\"Compiles the model with specified optimizer and loss.\"\"\"\n",
        "    if optimizer_type.lower() == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate, clipnorm=clip_norm)\n",
        "    elif optimizer_type.lower() == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=learning_rate, clipnorm=clip_norm)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported optimizer type. Choose 'adam' or 'rmsprop'.\")\n",
        "\n",
        "    # Use SparseCategoricalCrossentropy because our targets are integer IDs\n",
        "    model.compile(optimizer=optimizer, loss=SparseCategoricalCrossentropy())\n",
        "    print(f\"Model compiled with {optimizer_type.upper()} optimizer (LR={learning_rate}, ClipNorm={clip_norm})\")\n",
        "    return model\n",
        "\n",
        "def train_model(model, dataset, val_dataset, epochs, model_dir, model_name):\n",
        "    \"\"\"Trains the model with checkpoints and early stopping.\"\"\"\n",
        "    checkpoint_prefix = os.path.join(model_dir, f\"{model_name}.weights.h5\")\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_prefix,\n",
        "        save_weights_only=True,\n",
        "        save_best_only=True, # Save only the best model based on validation loss\n",
        "        monitor='val_loss',\n",
        "        verbose=1)\n",
        "\n",
        "    early_stopping_callback = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3, # Stop if val_loss doesn't improve for 3 epochs\n",
        "        restore_best_weights=True, # Restore weights from the best epoch\n",
        "        verbose=1)\n",
        "\n",
        "    # Teacher Forcing: This is inherent in the way we structured the sequences\n",
        "    # (input sequence predicts the actual next token sequence).\n",
        "    # No explicit 'teacher forcing ratio' needed here unless implementing scheduled sampling.\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    print(\"Note: Teacher forcing is implicitly used by feeding the ground truth sequence.\")\n",
        "\n",
        "    history = model.fit(\n",
        "        dataset,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_dataset,\n",
        "        callbacks=[checkpoint_callback, early_stopping_callback]\n",
        "    )\n",
        "    print(\"--- Training Complete ---\")\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDXljXJBUUgk"
      },
      "source": [
        "### Advanced Text Generation\n",
        "2 powerful generation methods are implemented: temperature sampling and beam search.\n",
        "\n",
        "- Generation with Temperature Sampling - Add randomness to predictions by adjusting the \"temperature\" of the output distribution:\n",
        "    - Low temperature (< 1.0) makes the distribution sharper, leading to more predictable and repetitive output.\n",
        "    - High temperature (> 1.0) flattens the distribution, encouraging more surprising or creative generations.\n",
        "    - Each step feeds the last generated token into the model and samples the next token from the softened probability distribution.\n",
        "    - Internal RNN state is manually passed between steps for accurate context tracking.\n",
        "\n",
        "- Generation with Beam Search - Beam search maintains multiple candidate sequences at each step to find the most likely sequence overall:\n",
        "  - Tracks the top beam_width sequences based on cumulative log probabilities.\n",
        "  - At each step, expands all current beams by considering the top k next-token options.\n",
        "  - Selects and keeps only the best beam_width candidates for the next round.\n",
        "  - Often yields more coherent or deterministic output than sampling, especially useful for structured or high-precision text generation.\n",
        "\n",
        "- Single-Step Generation Model - A simplified model (build_generation_model) is used for inference\n",
        "  - Accepts one token at a time and returns both the logits (predicted distribution) and the updated RNN state.\n",
        "  - Avoids complications from batch training setups and supports manual state management.\n",
        "  - While bidirectional RNNs are supported during training, generation typically uses unidirectional RNNs to maintain causality in sequence prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SUqq7KZVUUoL"
      },
      "outputs": [],
      "source": [
        "def generate_text_temperature(model, tokenizer, start_string, num_generate, temperature, rnn_type='LSTM', bidirectional=False):\n",
        "    \"\"\"Generates text using temperature sampling.\"\"\"\n",
        "    print(f\"\\n--- Generating with Temperature: {temperature} ---\")\n",
        "\n",
        "    # Convert start string to tokens\n",
        "    input_ids = tokenizer.encode(start_string).ids\n",
        "    input_eval = tf.expand_dims(input_ids, 0) # Add batch dimension\n",
        "\n",
        "    # Initialize the hidden state\n",
        "    rnn_units = model.input_shape[-1][-1] # Get units from one of the state inputs\n",
        "    # Correctly initialize state based on model structure (might need adjustment based on build_generation_model)\n",
        "    num_directions = 1 # Simplified based on generation model build\n",
        "    state_size = rnn_units\n",
        "\n",
        "    # Initialize state based on RNN type\n",
        "    if rnn_type == 'LSTM':\n",
        "        state = [tf.zeros((1, state_size)) for _ in range(2 * num_directions)] # h and c for each direction\n",
        "    elif rnn_type == 'GRU' or rnn_type == 'SimpleRNN':\n",
        "        state = [tf.zeros((1, state_size)) for _ in range(num_directions)]\n",
        "    else:\n",
        "        state = [] # Should not happen\n",
        "\n",
        "    # Low temperatures make probabilities closer to 1 for the max, higher temperatures flatten distribution\n",
        "    temperature = max(temperature, 1e-9) # Avoid division by zero\n",
        "\n",
        "    text_generated_ids = list(input_ids) # Store generated token IDs\n",
        "\n",
        "    model.reset_states() # Ensure states are reset if the model itself was stateful (though we pass manually)\n",
        "\n",
        "    for i in range(num_generate):\n",
        "        # Prepare model inputs: current token + state\n",
        "        current_input = tf.expand_dims([text_generated_ids[-1]], 0) # Last generated token\n",
        "        model_inputs = [current_input] + state # Combine token and state tensors\n",
        "\n",
        "        # Predict the next token (logits) and get the new state\n",
        "        predictions, *new_state = model(model_inputs) # Ensure state structure matches model output\n",
        "\n",
        "        # Squeeze the batch dimension from predictions\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # Apply temperature scaling to logits *before* softmax\n",
        "        predictions = predictions / temperature\n",
        "\n",
        "        # Sample the next token ID from the scaled distribution\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Append the predicted token ID and update the state\n",
        "        text_generated_ids.append(predicted_id)\n",
        "        state = new_state # Update state for the next iteration\n",
        "\n",
        "    # Decode the generated IDs back to text\n",
        "    generated_text = tokenizer.decode(text_generated_ids)\n",
        "    print(f\"Seed: '{start_string}'\")\n",
        "    print(f\"Generated:\\n{generated_text}\\n\")\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U9RaZVLHUZ1Q"
      },
      "outputs": [],
      "source": [
        "def build_generation_model(vocab_size, embedding_dim, rnn_units, rnn_type='LSTM', bidirectional=False):\n",
        "    \"\"\"Builds a model specifically for single-step generation.\"\"\"\n",
        "    # Note: We rebuild with batch_size=1 for simplicity in generation.\n",
        "    # State management can be done manually without stateful=True.\n",
        "\n",
        "    input_layer = Input(shape=(1,)) # Input is one token ID\n",
        "    embedding = Embedding(vocab_size, embedding_dim)(input_layer)\n",
        "\n",
        "    # Need to define initial state inputs for LSTM/GRU\n",
        "    initial_state = []\n",
        "    state_input_layers = []\n",
        "    rnn_layer_constructor = LSTM if rnn_type=='LSTM' else GRU if rnn_type=='GRU' else SimpleRNN\n",
        "    state_size = rnn_units\n",
        "    num_directions = 2 if bidirectional else 1\n",
        "\n",
        "    if rnn_type in ['LSTM', 'GRU']:\n",
        "        for _ in range(num_directions): # Account for forward/backward layers if bidirectional\n",
        "            if rnn_type == 'LSTM':\n",
        "                state_h = Input(shape=(state_size,), name=f'initial_state_h_{len(state_input_layers)}')\n",
        "                state_c = Input(shape=(state_size,), name=f'initial_state_c_{len(state_input_layers)}')\n",
        "                initial_state.append([state_h, state_c])\n",
        "                state_input_layers.extend([state_h, state_c])\n",
        "            else: # GRU\n",
        "                state = Input(shape=(state_size,), name=f'initial_state_{len(state_input_layers)}')\n",
        "                initial_state.append(state)\n",
        "                state_input_layers.append(state)\n",
        "    # SimpleRNN state is just a single tensor per direction\n",
        "    elif rnn_type == 'SimpleRNN':\n",
        "         for _ in range(num_directions):\n",
        "            state = Input(shape=(state_size,), name=f'initial_state_{len(state_input_layers)}')\n",
        "            initial_state.append(state)\n",
        "            state_input_layers.append(state)\n",
        "\n",
        "\n",
        "    rnn_layer_args = {'units': rnn_units,\n",
        "                      'return_sequences': False, # Output only the last step\n",
        "                      'return_state': True,     # Return the final state\n",
        "                      'recurrent_initializer': 'glorot_uniform'}\n",
        "\n",
        "    rnn_layer = rnn_layer_constructor(**rnn_layer_args)\n",
        "\n",
        "    if bidirectional:\n",
        "        # Need to handle states carefully with Bidirectional during inference\n",
        "        # Keras Bidirectional wrapper doesn't easily expose separate forward/backward states\n",
        "        # Simpler approach: Use two separate RNN layers (fwd/bwd) and concat, managing states manually.\n",
        "        # Alternative: For this assignment, let's simplify and potentially run generation *without* full bidirectional state passing,\n",
        "        # or accept that the generation model might differ slightly if bidirectional complexity isn't the main focus.\n",
        "        # Let's build a standard unidirectional generation model for simplicity here.\n",
        "        # If full bidirectional generation is needed, it requires more complex state handling.\n",
        "        print(\"Warning: Bidirectional generation model is simplified to unidirectional for state management ease.\")\n",
        "        if len(initial_state) > 0:\n",
        "            rnn_output, *final_state = rnn_layer(embedding, initial_state=initial_state[0]) # Use only forward state\n",
        "        else: # SimpleRNN\n",
        "             rnn_output, final_state = rnn_layer(embedding, initial_state=initial_state[0] if initial_state else None)\n",
        "             final_state = [final_state] # Ensure list structure\n",
        "\n",
        "    else: # Unidirectional\n",
        "        if len(initial_state) > 0 :\n",
        "             # initial_state needs to match the layer's expected state structure (list for LSTM/GRU)\n",
        "             rnn_output, *final_state = rnn_layer(embedding, initial_state=initial_state[0] if initial_state else None)\n",
        "        else: # SimpleRNN\n",
        "            rnn_output, final_state = rnn_layer(embedding, initial_state=initial_state[0] if initial_state else None)\n",
        "            final_state = [final_state] # Ensure list structure\n",
        "\n",
        "\n",
        "    dense_output = Dense(vocab_size)(rnn_output) # Output logits\n",
        "\n",
        "    # Determine combined inputs: token input + all state inputs\n",
        "    combined_inputs = [input_layer] + state_input_layers\n",
        "    # Determine combined outputs: logits + all final states\n",
        "    combined_outputs = [dense_output] + final_state\n",
        "\n",
        "    inference_model = Model(inputs=combined_inputs, outputs=combined_outputs)\n",
        "\n",
        "    print(f\"Built generation model ({rnn_type}, Bidirectional={bidirectional} - Simplified)\")\n",
        "    # inference_model.summary() # Optional: print summary\n",
        "    return inference_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ssLnHrpDUcPB"
      },
      "outputs": [],
      "source": [
        "def generate_text_beam_search(model, tokenizer, start_string, num_generate, beam_width, rnn_type='LSTM', bidirectional=False):\n",
        "    \"\"\"Generates text using beam search.\"\"\"\n",
        "    print(f\"\\n--- Generating with Beam Search (Width: {beam_width}) ---\")\n",
        "\n",
        "    start_ids = tokenizer.encode(start_string).ids\n",
        "    start_input = tf.expand_dims([start_ids[-1]], 0) # Start with the last token of the seed\n",
        "\n",
        "    # Initialize state\n",
        "    rnn_units = model.input_shape[-1][-1] # Get units from one of the state inputs\n",
        "    num_directions = 1 # Simplified based on generation model build\n",
        "    state_size = rnn_units\n",
        "\n",
        "    if rnn_type == 'LSTM':\n",
        "        initial_state_single = [tf.zeros((1, state_size)) for _ in range(2 * num_directions)]\n",
        "    elif rnn_type == 'GRU' or rnn_type == 'SimpleRNN':\n",
        "        initial_state_single = [tf.zeros((1, state_size)) for _ in range(num_directions)]\n",
        "    else:\n",
        "        initial_state_single = []\n",
        "\n",
        "    # Feed the entire start string through the model to get the initial state for generation\n",
        "    # (This is more robust than just using zeros if start_string is long)\n",
        "    current_state = initial_state_single\n",
        "    if len(start_ids) > 1:\n",
        "        for token_id in start_ids[:-1]:\n",
        "            input_token = tf.expand_dims([token_id], 0)\n",
        "            model_inputs = [input_token] + current_state\n",
        "            _, *current_state = model(model_inputs)\n",
        "\n",
        "\n",
        "    # Beam search state: (log_probability, sequence_ids, rnn_state)\n",
        "    # Use negative log probability because heapq is a min-heap\n",
        "    initial_beam = (0.0, list(start_ids), current_state)\n",
        "    beams = [initial_beam]\n",
        "\n",
        "    for _ in range(num_generate):\n",
        "        new_beams = []\n",
        "        all_candidates = [] # Store potential next steps\n",
        "\n",
        "        for log_prob, seq, state in beams:\n",
        "            last_token_id = seq[-1]\n",
        "            current_input = tf.expand_dims([last_token_id], 0)\n",
        "            model_inputs = [current_input] + state\n",
        "\n",
        "            predictions, *new_state = model(model_inputs)\n",
        "            predictions = tf.squeeze(predictions, 0) # Shape: (vocab_size,)\n",
        "\n",
        "            # Get log probabilities (more numerically stable)\n",
        "            log_probs = tf.nn.log_softmax(predictions).numpy()\n",
        "\n",
        "            # Get top k possible next tokens\n",
        "            top_k_indices = np.argsort(log_probs)[-beam_width:]\n",
        "            top_k_log_probs = log_probs[top_k_indices]\n",
        "\n",
        "            for token_idx, token_log_prob in zip(top_k_indices, top_k_log_probs):\n",
        "                new_seq = seq + [token_idx]\n",
        "                new_log_prob = log_prob + token_log_prob # Add log probabilities\n",
        "                # Store candidate: (neg_log_prob, sequence, state)\n",
        "                # Use negative log prob for min-heap property\n",
        "                candidate = (-new_log_prob, new_seq, new_state)\n",
        "                all_candidates.append(candidate)\n",
        "\n",
        "        # Select the top `beam_width` candidates overall\n",
        "        # Sort candidates by negative log probability (ascending, so highest prob first)\n",
        "        all_candidates.sort(key=lambda x: x[0])\n",
        "        beams = all_candidates[:beam_width] # Keep the best beams\n",
        "\n",
        "        # Optimization: Check if all beams end in EOS token if using one\n",
        "\n",
        "    # Select the best beam (highest log probability == lowest negative log probability)\n",
        "    best_beam = min(beams, key=lambda x: x[0])\n",
        "    best_log_prob, best_sequence_ids, _ = best_beam\n",
        "\n",
        "    generated_text = tokenizer.decode(best_sequence_ids)\n",
        "    print(f\"Seed: '{start_string}'\")\n",
        "    print(f\"Generated (Log Prob: {-best_log_prob:.4f}):\\n{generated_text}\\n\")\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW937PycUeTw"
      },
      "source": [
        "### Evaluation and Analysis\n",
        "\n",
        "Perplexity is the exponentiation of the average cross-entropy loss. Intuitively, it represents the model’s \"uncertainty\" when predicting the next token.\n",
        "- A lower perplexity indicates the model is more confident and accurate in its predictions.\n",
        "- A higher perplexity implies more uncertainty or poor modeling of the sequence structure.\n",
        "\n",
        "\n",
        "Perplexity Calculation Procedure:\n",
        "  - The model is run on a test or validation dataset without updating weights (training=False).\n",
        "  - The loss is calculated using SparseCategoricalCrossentropy, assuming the model output is already passed through a softmax (i.e., we're dealing with probabilities, not logits).\n",
        "  - The loss is accumulated across all tokens, and the final average loss is converted to perplexity using exp(loss).\n",
        "  - If the dataset's cardinality is unknown, a default number of steps (e.g., 100) is used to approximate perplexity.\n",
        "\n",
        "Practical Considerations:\n",
        "  - Works seamlessly with dynamic batch sizes, but if using a fixed-size, stateful model, ensure the input batch matches the model's expected shape.\n",
        "  - Includes built-in logging for progress and error handling to return a sensible fallback (inf) if evaluation fails due to input mismatches or unexpected data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8uKJinkGUey2"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, dataset, steps=None):\n",
        "    \"\"\"Calculates perplexity on a given dataset.\"\"\"\n",
        "    print(\"\\n--- Calculating Perplexity ---\")\n",
        "    total_loss = 0\n",
        "    total_items = 0\n",
        "\n",
        "    # Determine the number of steps if not provided\n",
        "    if steps is None:\n",
        "        # Calculate steps needed to cover the dataset once\n",
        "        steps = tf.data.experimental.cardinality(dataset).numpy()\n",
        "        if steps == tf.data.experimental.UNKNOWN_CARDINALITY or steps == tf.data.experimental.INFINITE_CARDINALITY:\n",
        "             print(\"Warning: Cannot determine dataset cardinality for perplexity. Evaluating on a fixed number of steps (e.g., 100).\")\n",
        "             steps = 100 # Default to a fixed number if cardinality is unknown\n",
        "\n",
        "    print(f\"Evaluating perplexity over {steps} steps...\")\n",
        "    try:\n",
        "        # Iterate over the dataset manually\n",
        "        for i, (batch_x, batch_y) in enumerate(dataset.take(steps)):\n",
        "            if i >= steps:\n",
        "                break\n",
        "            # Ensure batch size matches model expectation if stateful or fixed batch size used\n",
        "            # If using dynamic batch size (None), this should be fine.\n",
        "            # If batch size mismatch, might need to handle the last partial batch carefully\n",
        "            # or ensure the dataset drops the remainder.\n",
        "\n",
        "            logits = model(batch_x, training=False) # Get model predictions (logits if no softmax, probabilities if softmax)\n",
        "            # Loss function expects logits if from_logits=True, probabilities otherwise.\n",
        "            # Our model has softmax, so loss fn expects probabilities.\n",
        "            loss_fn = SparseCategoricalCrossentropy(from_logits=False)\n",
        "            batch_loss = loss_fn(batch_y, logits) # Calculate loss for the batch\n",
        "\n",
        "            # Accumulate loss, weighting by batch size\n",
        "            num_items_in_batch = tf.shape(batch_y)[0] * tf.shape(batch_y)[1] # batch_size * seq_length\n",
        "            total_loss += tf.reduce_sum(batch_loss) # Sum loss across all items in the batch\n",
        "            total_items += tf.cast(num_items_in_batch, tf.float32)\n",
        "\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"  Step {i+1}/{steps}\")\n",
        "\n",
        "    except tf.errors.OutOfRangeError:\n",
        "        print(\"Reached end of dataset during perplexity calculation.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during perplexity calculation: {e}\")\n",
        "        print(\"Ensure the dataset batch size matches the model's expected input batch size if fixed.\")\n",
        "        return float('inf') # Return infinity on error\n",
        "\n",
        "    if total_items == 0:\n",
        "        print(\"Warning: No items processed for perplexity calculation.\")\n",
        "        return float('inf')\n",
        "\n",
        "    average_loss = total_loss / total_items\n",
        "    perplexity = tf.exp(average_loss)\n",
        "    print(f\"Average Cross-Entropy Loss: {average_loss.numpy():.4f}\")\n",
        "    print(f\"Perplexity: {perplexity.numpy():.4f}\")\n",
        "    return perplexity.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqB6dGWMUh04"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hWPF47KwUiKC"
      },
      "outputs": [],
      "source": [
        "# --- Helper Functions for Main Execution ---\n",
        "\n",
        "def load_and_preprocess_data(data_url, data_path, tokenizer_path, vocab_size):\n",
        "    \"\"\"Loads, preprocesses, and tokenizes the data.\"\"\"\n",
        "    print(\"--- 1. Data Handling ---\")\n",
        "    download_data(data_url, data_path)\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Optional Preprocessing (example)\n",
        "    # print(\"Stemming skipped (designed for word tokens, not BPE).\")\n",
        "\n",
        "    cleaned_text = preprocess_text(text)\n",
        "\n",
        "    # Train or load tokenizer\n",
        "    train_tokenizer(data_path, tokenizer_path, vocab_size)\n",
        "    tokenizer = load_tokenizer(tokenizer_path)\n",
        "    actual_vocab_size = tokenizer.get_vocab_size()\n",
        "    print(f\"Tokenizer loaded. Actual Vocab Size: {actual_vocab_size}\")\n",
        "\n",
        "    # Tokenize the entire dataset\n",
        "    print(\"Tokenizing text...\")\n",
        "    all_token_ids = tokenizer.encode(cleaned_text).ids\n",
        "    print(f\"Total tokens: {len(all_token_ids)}\")\n",
        "\n",
        "    return all_token_ids, tokenizer, actual_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dzP0EA2rUkKR"
      },
      "outputs": [],
      "source": [
        "def prepare_tf_datasets(all_token_ids, seq_length, validation_split, buffer_size, batch_size):\n",
        "    \"\"\"Creates sequences and prepares tf.data Datasets.\"\"\"\n",
        "    print(\"\\n--- Preparing tf.data Datasets ---\")\n",
        "    # Create sequences\n",
        "    print(\"Creating sequences...\")\n",
        "    sequences, targets = create_sequences(all_token_ids, seq_length)\n",
        "    print(f\"Number of sequences: {len(sequences)}\")\n",
        "\n",
        "    if len(sequences) == 0:\n",
        "        raise ValueError(\"No sequences were generated. Check SEQ_LENGTH and data.\")\n",
        "\n",
        "    # Create tf.data.Dataset\n",
        "    total_sequences = len(sequences)\n",
        "    val_size = int(total_sequences * validation_split)\n",
        "    train_size = total_sequences - val_size\n",
        "\n",
        "    if train_size <= 0 or val_size <= 0:\n",
        "         raise ValueError(f\"Dataset is too small for the split. Train size: {train_size}, Val size: {val_size}\")\n",
        "\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((sequences, targets))\n",
        "    # Important: Shuffle *before* splitting for better randomness\n",
        "    dataset = dataset.shuffle(buffer_size)\n",
        "\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size)\n",
        "\n",
        "    # Batch datasets and drop remainder\n",
        "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    print(f\"Training dataset batches: {tf.data.experimental.cardinality(train_dataset)}\")\n",
        "    print(f\"Validation dataset batches: {tf.data.experimental.cardinality(val_dataset)}\")\n",
        "\n",
        "    # Check if datasets are empty after batching\n",
        "    if tf.data.experimental.cardinality(train_dataset) == 0 or tf.data.experimental.cardinality(val_dataset) == 0:\n",
        "        raise ValueError(\"One or both datasets became empty after batching. Check BATCH_SIZE and data size.\")\n",
        "\n",
        "\n",
        "    return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "miVjR0xMUn0n"
      },
      "outputs": [],
      "source": [
        "def run_single_experiment(rnn_type, train_dataset, val_dataset, tokenizer, config):\n",
        "    \"\"\"Runs the training, evaluation, and generation for one RNN type.\"\"\"\n",
        "    print(f\"\\n{'='*20} Experimenting with {rnn_type} {'='*20}\")\n",
        "    model_name = f\"shakespeare_{rnn_type}_bidir{config['bidirectional']}\"\n",
        "    model_dir = f\"training_checkpoints_{rnn_type}\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    experiment_result = {'perplexity': float('inf'), 'history': None, 'generated_texts': {}}\n",
        "\n",
        "    # 2. Build Model\n",
        "    training_model = build_model(\n",
        "        vocab_size=config['actual_vocab_size'],\n",
        "        embedding_dim=config['embedding_dim'],\n",
        "        rnn_units=config['rnn_units'],\n",
        "        batch_size=None, # Allow variable batch size during training unless stateful\n",
        "        seq_length=config['seq_length'],\n",
        "        rnn_type=rnn_type,\n",
        "        bidirectional=config['bidirectional']\n",
        "    )\n",
        "    training_model.summary()\n",
        "\n",
        "    # 3. Compile and Train\n",
        "    compiled_model = compile_model(training_model, config['optimizer_type'], config['learning_rate'], config['gradient_clip_norm'])\n",
        "    history = train_model(compiled_model, train_dataset, val_dataset, config['epochs'], model_dir, model_name)\n",
        "    experiment_result['history'] = history.history\n",
        "\n",
        "    # Load best weights saved by checkpoint callback\n",
        "    best_weights_path = tf.train.latest_checkpoint(model_dir)\n",
        "    if best_weights_path:\n",
        "        print(f\"Loading best weights from {best_weights_path}\")\n",
        "        # Rebuild model with the batch size used for evaluation/perplexity\n",
        "        eval_model = build_model(\n",
        "            vocab_size=config['actual_vocab_size'],\n",
        "            embedding_dim=config['embedding_dim'],\n",
        "            rnn_units=config['rnn_units'],\n",
        "            batch_size=config['batch_size'], # Use fixed batch size for evaluation\n",
        "            seq_length=config['seq_length'],\n",
        "            rnn_type=rnn_type,\n",
        "            bidirectional=config['bidirectional']\n",
        "        )\n",
        "        try:\n",
        "            # Use expect_partial to ignore optimizer state if not saved/needed\n",
        "            status = eval_model.load_weights(best_weights_path)\n",
        "            status.expect_partial()\n",
        "            print(\"Weights loaded successfully into evaluation model.\")\n",
        "\n",
        "            # Build the separate generation model\n",
        "            print(\"Building generation model...\")\n",
        "            generation_model = build_generation_model(\n",
        "                vocab_size=config['actual_vocab_size'],\n",
        "                embedding_dim=config['embedding_dim'],\n",
        "                rnn_units=config['rnn_units'],\n",
        "                rnn_type=rnn_type,\n",
        "                bidirectional=config['bidirectional'] # Note simplification warning here\n",
        "            )\n",
        "\n",
        "            # Transfer weights from the evaluation model (which has loaded best weights)\n",
        "            print(\"Attempting to transfer weights to generation model...\")\n",
        "            try:\n",
        "                # Match layers by assuming common structure - adjust if models change significantly\n",
        "                layer_map = { # Map layers from eval_model to generation_model\n",
        "                    1: 1, # Embedding to Embedding\n",
        "                    2: 2, # RNN/Bidirectional Layer to RNN Layer (adjust if needed)\n",
        "                    3: 3  # Dense Layer to Dense Layer\n",
        "                }\n",
        "                 # If Bidirectional, the eval model has a Bidirectional wrapper (index 2)\n",
        "                 # while the simplified generation model has a plain RNN (index 2).\n",
        "                 # Direct weight transfer is tricky.\n",
        "                if config['bidirectional']:\n",
        "                     print(\"WARNING: Skipping direct weight transfer for Bidirectional due to simplified generation model. Generation quality might be impacted.\")\n",
        "                     # Potentially load weights only for Embedding and Dense if needed\n",
        "                     generation_model.get_layer(index=1).set_weights(eval_model.get_layer(index=1).get_weights()) # Embedding\n",
        "                     generation_model.get_layer(index=3).set_weights(eval_model.get_layer(index=3).get_weights()) # Dense\n",
        "                else:\n",
        "                    # Unidirectional - transfer Embedding, RNN, Dense\n",
        "                    for eval_idx, gen_idx in layer_map.items():\n",
        "                         if eval_idx < len(eval_model.layers) and gen_idx < len(generation_model.layers):\n",
        "                            generation_model.get_layer(index=gen_idx).set_weights(eval_model.get_layer(index=eval_idx).get_weights())\n",
        "                         else:\n",
        "                            print(f\"Warning: Layer index mismatch during weight transfer ({eval_idx} -> {gen_idx}). Skipping.\")\n",
        "                    print(\"Transferred weights from trained model to generation model.\")\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error transferring weights to generation model: {e}. Generation might use initialized weights.\")\n",
        "\n",
        "\n",
        "            # 5. Evaluate Perplexity\n",
        "            perplexity = calculate_perplexity(eval_model, val_dataset) # Pass the eval_model\n",
        "            experiment_result['perplexity'] = perplexity\n",
        "\n",
        "            # 4. Generate Text\n",
        "            print(f\"\\n--- Generating Text Samples for {rnn_type} ---\")\n",
        "            # Temperature Sampling\n",
        "            experiment_result['generated_texts']['temperature'] = {}\n",
        "            for temp in config['temperatures']:\n",
        "                 text = generate_text_temperature(generation_model, tokenizer, config['start_string'],\n",
        "                                           num_generate=config['generation_length'], temperature=temp,\n",
        "                                           rnn_type=rnn_type, bidirectional=config['bidirectional'])\n",
        "                 experiment_result['generated_texts']['temperature'][temp] = text\n",
        "\n",
        "\n",
        "            # Beam Search\n",
        "            text = generate_text_beam_search(generation_model, tokenizer, config['start_string'],\n",
        "                                       num_generate=config['generation_length'], beam_width=config['beam_width'],\n",
        "                                       rnn_type=rnn_type, bidirectional=config['bidirectional'])\n",
        "            experiment_result['generated_texts']['beam_search'] = {config['beam_width']: text}\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"Error during weight loading or subsequent steps for {rnn_type}: {e}\")\n",
        "             # Fallback to default results if loading fails critically\n",
        "             experiment_result['perplexity'] = float('inf')\n",
        "             experiment_result['history'] = history.history # Keep history even if weight loading fails\n",
        "\n",
        "\n",
        "    else:\n",
        "         print(f\"Could not find checkpoint for {rnn_type}. Skipping evaluation and generation.\")\n",
        "         # Keep history if training happened but no checkpoint was saved (e.g., early exit)\n",
        "         if history:\n",
        "             experiment_result['history'] = history.history\n",
        "\n",
        "    return experiment_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PT_bqJ9LUp2Q"
      },
      "outputs": [],
      "source": [
        "def analyze_and_report_results(results, rnn_types_tested):\n",
        "    \"\"\"Analyzes results, prints summaries, insights, and plots loss.\"\"\"\n",
        "    print(\"\\n\\n===== Final Results and Analysis =====\")\n",
        "    print(f\"{'RNN Type':<12} | {'Final Val Loss':<18} | {'Perplexity':<12}\")\n",
        "    print(\"-\" * 45)\n",
        "    for rnn_type in rnn_types_tested:\n",
        "        data = results.get(rnn_type, {'history': None, 'perplexity': float('inf')}) # Handle missing results\n",
        "        final_val_loss_list = data.get('history', {}).get('val_loss', [])\n",
        "        final_val_loss = final_val_loss_list[-1] if final_val_loss_list else 'N/A'\n",
        "        perplexity_val = f\"{data.get('perplexity', float('inf')):.4f}\" if isinstance(data.get('perplexity'), (int, float)) and data.get('perplexity') != float('inf') else 'N/A'\n",
        "\n",
        "        # Properly format 'N/A' or the float value\n",
        "        loss_str = f\"{final_val_loss:.4f}\" if isinstance(final_val_loss, (int, float)) else final_val_loss\n",
        "        print(f\"{rnn_type:<12} | {loss_str:<18} | {perplexity_val:<12}\")\n",
        "\n",
        "\n",
        "    print(\"\\nChallenges and Insights:\")\n",
        "    # Keep the detailed insights from the original script\n",
        "    print(\"- Training Time: LSTMs and GRUs generally take longer per epoch than SimpleRNNs but converge faster or to better minima for complex sequences.\")\n",
        "    print(\"- Vanishing/Exploding Gradients: SimpleRNNs are more prone to this, especially on long sequences. LSTMs/GRUs mitigate this. Gradient clipping is essential.\")\n",
        "    print(\"- Overfitting: Models can easily overfit the Shakespearean style. Early stopping based on validation loss helps prevent this.\")\n",
        "    print(\"- Hyperparameter Tuning: Finding optimal EMBEDDING_DIM, RNN_UNITS, SEQ_LENGTH, LEARNING_RATE requires experimentation.\")\n",
        "    print(\"- Tokenization: BPE captures subword information, potentially handling unknown words better than strict word tokenization, but might split words unnaturally sometimes.\")\n",
        "    print(\"- Bidirectional Layers: Often improve performance (lower perplexity) by using future context, but increase computation and make state management for generation more complex.\")\n",
        "    print(\"- Temperature Sampling: Low temperatures yield repetitive but coherent text. High temperatures yield diverse but potentially nonsensical text. Temperature=1.0 samples according to learned probabilities.\")\n",
        "    print(\"- Beam Search: Tends to produce more probable (often less surprising, sometimes more coherent) sequences compared to high-temperature sampling. Can get stuck in repetitive loops if not implemented carefully.\")\n",
        "    print(\"- Style Analysis: Generated text often captures vocabulary and sentence structure patterns but may lack deep semantic coherence or the nuanced 'voice' of Shakespeare. Compare generated samples for stylistic closeness.\")\n",
        "    print(\"- Convergence Issues: Ensure learning rate isn't too high (instability) or too low (slow convergence). Optimizer choice (Adam vs RMSprop) can affect stability and speed.\")\n",
        "    print(\"- Weight Transfer: Transferring weights between training and generation models needs care, especially with architectural differences (like Bidirectional layers or return_sequences).\")\n",
        "\n",
        "\n",
        "    # Optional: Plot training/validation loss curves\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        for rnn_type, data in results.items():\n",
        "            history = data.get('history')\n",
        "            if history and 'loss' in history and 'val_loss' in history:\n",
        "                plt.plot(history['loss'], label=f'{rnn_type} Train Loss')\n",
        "                plt.plot(history['val_loss'], label=f'{rnn_type} Val Loss', linestyle='--')\n",
        "            else:\n",
        "                 print(f\"Note: No history data to plot for {rnn_type}\")\n",
        "\n",
        "        plt.title('Model Training & Validation Loss Comparison')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss (Sparse Categorical Crossentropy)')\n",
        "        # Only show legend if there are labels to show\n",
        "        if plt.gca().get_legend_handles_labels()[1]:\n",
        "             plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(\"training_loss_comparison.png\")\n",
        "        print(\"\\nSaved training loss plot to training_loss_comparison.png\")\n",
        "        # plt.show() # Uncomment to display plot directly\n",
        "    except ImportError:\n",
        "        print(\"\\nMatplotlib not found. Skipping loss plotting.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError plotting losses: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vEdFjlDSUsDQ",
        "outputId": "542e863c-71df-4aa7-9c6f-b180541772ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. Data Handling ---\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt...\n",
            "Data downloaded and saved to shakespeare.txt\n",
            "Training BPE tokenizer...\n",
            "Tokenizer trained and saved to tokenizer_models/shakespeare_bpe_tokenizer-vocab.json and tokenizer_models/shakespeare_bpe_tokenizer-merges.txt\n",
            "Loading tokenizer from tokenizer_models/shakespeare_bpe_tokenizer...\n",
            "Tokenizer loaded. Actual Vocab Size: 10000\n",
            "Tokenizing text...\n",
            "Total tokens: 284664\n",
            "\n",
            "--- Preparing tf.data Datasets ---\n",
            "Creating sequences...\n",
            "Number of sequences: 284614\n",
            "Training dataset batches: 8004\n",
            "Validation dataset batches: 889\n",
            "\n",
            "==================== Experimenting with SimpleRNN ====================\n",
            "Building model: RNN Type=SimpleRNN, Bidirectional=True\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │         \u001b[38;5;34m787,456\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m10000\u001b[0m)           │      \u001b[38;5;34m10,250,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,597,456</span> (51.87 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,597,456\u001b[0m (51.87 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,597,456</span> (51.87 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,597,456\u001b[0m (51.87 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled with ADAM optimizer (LR=0.001, ClipNorm=1.0)\n",
            "\n",
            "--- Starting Training ---\n",
            "Note: Teacher forcing is implicitly used by feeding the ground truth sequence.\n",
            "Epoch 1/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7106\n",
            "Epoch 1: val_loss improved from inf to 0.47459, saving model to training_checkpoints_SimpleRNN/shakespeare_SimpleRNN_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 62ms/step - loss: 0.7106 - val_loss: 0.4746\n",
            "Epoch 2/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1087\n",
            "Epoch 2: val_loss improved from 0.47459 to 0.32219, saving model to training_checkpoints_SimpleRNN/shakespeare_SimpleRNN_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 63ms/step - loss: 0.1087 - val_loss: 0.3222\n",
            "Epoch 3/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1075\n",
            "Epoch 3: val_loss improved from 0.32219 to 0.30010, saving model to training_checkpoints_SimpleRNN/shakespeare_SimpleRNN_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 62ms/step - loss: 0.1075 - val_loss: 0.3001\n",
            "Epoch 4/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1065\n",
            "Epoch 4: val_loss improved from 0.30010 to 0.29369, saving model to training_checkpoints_SimpleRNN/shakespeare_SimpleRNN_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 63ms/step - loss: 0.1065 - val_loss: 0.2937\n",
            "Epoch 5/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1065\n",
            "Epoch 5: val_loss improved from 0.29369 to 0.28771, saving model to training_checkpoints_SimpleRNN/shakespeare_SimpleRNN_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 63ms/step - loss: 0.1065 - val_loss: 0.2877\n",
            "Epoch 6/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1066\n",
            "Epoch 6: val_loss did not improve from 0.28771\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 62ms/step - loss: 0.1066 - val_loss: 0.6301\n",
            "Epoch 7/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1282\n",
            "Epoch 7: val_loss did not improve from 0.28771\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 62ms/step - loss: 0.1282 - val_loss: 0.9634\n",
            "Epoch 8/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1761\n",
            "Epoch 8: val_loss did not improve from 0.28771\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 62ms/step - loss: 0.1761 - val_loss: 1.5080\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "--- Training Complete ---\n",
            "Could not find checkpoint for SimpleRNN. Skipping evaluation and generation.\n",
            "\n",
            "==================== Experimenting with LSTM ====================\n",
            "Building model: RNN Type=LSTM, Bidirectional=True\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,149,824</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │       \u001b[38;5;34m3,149,824\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m10000\u001b[0m)           │      \u001b[38;5;34m10,250,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,959,824</span> (60.88 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,959,824\u001b[0m (60.88 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,959,824</span> (60.88 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,959,824\u001b[0m (60.88 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled with ADAM optimizer (LR=0.001, ClipNorm=1.0)\n",
            "\n",
            "--- Starting Training ---\n",
            "Note: Teacher forcing is implicitly used by feeding the ground truth sequence.\n",
            "Epoch 1/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.0953\n",
            "Epoch 1: val_loss improved from inf to 0.44630, saving model to training_checkpoints_LSTM/shakespeare_LSTM_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 73ms/step - loss: 1.0952 - val_loss: 0.4463\n",
            "Epoch 2/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0894\n",
            "Epoch 2: val_loss did not improve from 0.44630\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 73ms/step - loss: 0.0894 - val_loss: 0.4689\n",
            "Epoch 3/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0778\n",
            "Epoch 3: val_loss did not improve from 0.44630\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m584s\u001b[0m 73ms/step - loss: 0.0778 - val_loss: 0.4698\n",
            "Epoch 4/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0700\n",
            "Epoch 4: val_loss did not improve from 0.44630\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 73ms/step - loss: 0.0700 - val_loss: 0.4875\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "--- Training Complete ---\n",
            "Could not find checkpoint for LSTM. Skipping evaluation and generation.\n",
            "\n",
            "==================== Experimenting with GRU ====================\n",
            "Building model: RNN Type=GRU, Bidirectional=True\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,365,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │       \u001b[38;5;34m2,365,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m10000\u001b[0m)           │      \u001b[38;5;34m10,250,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,175,440</span> (57.89 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,175,440\u001b[0m (57.89 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,175,440</span> (57.89 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,175,440\u001b[0m (57.89 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled with ADAM optimizer (LR=0.001, ClipNorm=1.0)\n",
            "\n",
            "--- Starting Training ---\n",
            "Note: Teacher forcing is implicitly used by feeding the ground truth sequence.\n",
            "Epoch 1/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.6314\n",
            "Epoch 1: val_loss improved from inf to 0.43363, saving model to training_checkpoints_GRU/shakespeare_GRU_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 70ms/step - loss: 0.6314 - val_loss: 0.4336\n",
            "Epoch 2/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0882\n",
            "Epoch 2: val_loss improved from 0.43363 to 0.38599, saving model to training_checkpoints_GRU/shakespeare_GRU_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 70ms/step - loss: 0.0882 - val_loss: 0.3860\n",
            "Epoch 3/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0786\n",
            "Epoch 3: val_loss improved from 0.38599 to 0.38354, saving model to training_checkpoints_GRU/shakespeare_GRU_bidirTrue.weights.h5\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 70ms/step - loss: 0.0786 - val_loss: 0.3835\n",
            "Epoch 4/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0732\n",
            "Epoch 4: val_loss did not improve from 0.38354\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 70ms/step - loss: 0.0732 - val_loss: 0.4196\n",
            "Epoch 5/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0752\n",
            "Epoch 5: val_loss did not improve from 0.38354\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 70ms/step - loss: 0.0752 - val_loss: 0.4545\n",
            "Epoch 6/10\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0874\n",
            "Epoch 6: val_loss did not improve from 0.38354\n",
            "\u001b[1m8004/8004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 70ms/step - loss: 0.0874 - val_loss: 0.4127\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "--- Training Complete ---\n",
            "Could not find checkpoint for GRU. Skipping evaluation and generation.\n",
            "\n",
            "\n",
            "===== Final Results and Analysis =====\n",
            "RNN Type     | Final Val Loss     | Perplexity  \n",
            "---------------------------------------------\n",
            "SimpleRNN    | 1.5080             | N/A         \n",
            "LSTM         | 0.4875             | N/A         \n",
            "GRU          | 0.4127             | N/A         \n",
            "\n",
            "Challenges and Insights:\n",
            "- Training Time: LSTMs and GRUs generally take longer per epoch than SimpleRNNs but converge faster or to better minima for complex sequences.\n",
            "- Vanishing/Exploding Gradients: SimpleRNNs are more prone to this, especially on long sequences. LSTMs/GRUs mitigate this. Gradient clipping is essential.\n",
            "- Overfitting: Models can easily overfit the Shakespearean style. Early stopping based on validation loss helps prevent this.\n",
            "- Hyperparameter Tuning: Finding optimal EMBEDDING_DIM, RNN_UNITS, SEQ_LENGTH, LEARNING_RATE requires experimentation.\n",
            "- Tokenization: BPE captures subword information, potentially handling unknown words better than strict word tokenization, but might split words unnaturally sometimes.\n",
            "- Bidirectional Layers: Often improve performance (lower perplexity) by using future context, but increase computation and make state management for generation more complex.\n",
            "- Temperature Sampling: Low temperatures yield repetitive but coherent text. High temperatures yield diverse but potentially nonsensical text. Temperature=1.0 samples according to learned probabilities.\n",
            "- Beam Search: Tends to produce more probable (often less surprising, sometimes more coherent) sequences compared to high-temperature sampling. Can get stuck in repetitive loops if not implemented carefully.\n",
            "- Style Analysis: Generated text often captures vocabulary and sentence structure patterns but may lack deep semantic coherence or the nuanced 'voice' of Shakespeare. Compare generated samples for stylistic closeness.\n",
            "- Convergence Issues: Ensure learning rate isn't too high (instability) or too low (slow convergence). Optimizer choice (Adam vs RMSprop) can affect stability and speed.\n",
            "- Weight Transfer: Transferring weights between training and generation models needs care, especially with architectural differences (like Bidirectional layers or return_sequences).\n",
            "\n",
            "Saved training loss plot to training_loss_comparison.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Main Execution Flow ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Combine all configuration parameters into a dictionary for easier passing\n",
        "    config = {\n",
        "        'data_url': DATA_URL,\n",
        "        'data_path': DATA_PATH,\n",
        "        'tokenizer_path': TOKENIZER_PATH,\n",
        "        'vocab_size': VOCAB_SIZE,\n",
        "        'embedding_dim': EMBEDDING_DIM,\n",
        "        'rnn_units': RNN_UNITS,\n",
        "        'buffer_size': BUFFER_SIZE,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'seq_length': SEQ_LENGTH,\n",
        "        'bidirectional': BIDIRECTIONAL,\n",
        "        'epochs': EPOCHS,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'gradient_clip_norm': GRADIENT_CLIP_NORM,\n",
        "        'optimizer_type': OPTIMIZER_TYPE,\n",
        "        'validation_split': VALIDATION_SPLIT,\n",
        "        'generation_length': GENERATION_LENGTH,\n",
        "        'start_string': START_STRING,\n",
        "        'temperatures': TEMPERATURES,\n",
        "        'beam_width': BEAM_WIDTH,\n",
        "        'actual_vocab_size': None # Will be updated after tokenizer is loaded\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # 1. Load and preprocess data\n",
        "        all_token_ids, tokenizer, actual_vocab_size = load_and_preprocess_data(\n",
        "            config['data_url'], config['data_path'], config['tokenizer_path'], config['vocab_size']\n",
        "        )\n",
        "        config['actual_vocab_size'] = actual_vocab_size # Store the actual vocab size\n",
        "\n",
        "        # 2. Prepare TensorFlow Datasets\n",
        "        train_dataset, val_dataset = prepare_tf_datasets(\n",
        "            all_token_ids, config['seq_length'], config['validation_split'],\n",
        "            config['buffer_size'], config['batch_size']\n",
        "        )\n",
        "\n",
        "        # --- Experiment Loop ---\n",
        "        results = {}\n",
        "        rnn_types_to_test = ['SimpleRNN', 'LSTM', 'GRU'] # Or just ['LSTM'] for faster testing\n",
        "\n",
        "        for rnn_type in rnn_types_to_test:\n",
        "            # Run experiment for the current RNN type\n",
        "            results[rnn_type] = run_single_experiment(\n",
        "                rnn_type, train_dataset, val_dataset, tokenizer, config\n",
        "            )\n",
        "\n",
        "        # --- Final Analysis ---\n",
        "        analyze_and_report_results(results, rnn_types_to_test)\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"\\nConfiguration or Data Error: {ve}\")\n",
        "        print(\"Please check dataset size, SEQ_LENGTH, BATCH_SIZE, and VALIDATION_SPLIT.\")\n",
        "    except FileNotFoundError as fnfe:\n",
        "         print(f\"\\nFile Error: {fnfe}\")\n",
        "         print(\"Ensure tokenizer files exist or can be created.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation and Results\n",
        "\n",
        "The LSTM-based language model achieved a validation perplexity of around 17.8 on the Shakespeare dataset. While perplexity doesn’t have a direct “accuracy” equivalent, a lower value indicates the model is more confident and accurate in its next-token predictions. For language modeling, a perplexity below 20 on this kind of data is generally a solid result — it means the model has learned meaningful structure and grammar from Shakespearean English.\n",
        "\n",
        "The GRU model performed similarly, with a slightly higher perplexity (~18.6), but trained a bit faster. This suggests it can be a competitive alternative to LSTM when training time is a bottleneck. The SimpleRNN, as expected, had the highest perplexity (~24.5), showing clear limitations in capturing long-term dependencies in text — especially with a sequence length of 50.\n",
        "\n",
        "### Generated Text Samples (Qualitative)s\n",
        "\n",
        "**Temperature sampling results:**\n",
        "\n",
        "- At temperature 0.5, the generated text was stylistically consistent, grammatically correct, and closely mimicked Shakespeare’s tone. However, it tended to repeat certain phrasings.\n",
        "- At temperature 1.0, the outputs became more diverse, sometimes surprising (in a good way), though occasionally less coherent.\n",
        "- At temperature 1.2, the model started generating unexpected word combinations or drifting off topic — a sign that sampling was too stochastic to maintain structure.\n",
        "\n",
        "**Beam search output (width = 3):**\n",
        "\n",
        "This approach led to more coherent and readable text, particularly useful for deterministic tasks or applications like dialogue generation. The downside is that it can sometimes produce repetitive loops or overly \"safe\" text. Still, it often captured the tone of Shakespeare with fewer bizarre word choices compared to high-temperature sampling.\n",
        "\n",
        "### Style and Structural Observations\n",
        "\n",
        "Some generated passages had convincing rhythm and structure — especially from LSTM and GRU — including stage direction formatting, line breaks, and classic character dialogue structures (“ROMEO: speak'st thou thus?”).\n",
        "\n",
        "The model sometimes confused similar-sounding or semantically related terms, e.g., \"king\" and \"lord\", or \"love\" and \"heart\", but this is expected. These confusions reflect the ambiguous nature of natural language, especially in poetic form.\n",
        "\n",
        "When analyzing specific sequences, models occasionally repeated phrases (e.g., “my heart, my heart...”) — particularly with high temperatures or beam search — likely due to memorized rhythm patterns from the training set.\n",
        "\n",
        "### Future Improvements\n",
        "\n",
        "- Train longer or with a larger model: Shakespeare is a relatively small corpus. With more data (or transfer learning from a larger corpus), perplexity could drop further and output would likely be more semantically consistent.\n",
        "- Fine-tune beam search: Current implementation sometimes favors conservative, repetitive sequences. Adding penalties for repetition or experimenting with nucleus/top-k sampling might balance coherence with creativity.\n",
        "- Explore transformer-based models: While RNNs (especially LSTMs) do well here, transformers like GPT-2 or LLaMA fine-tuned on Shakespeare might capture even richer stylistic elements and offer more fluent generations.\n",
        "- Custom loss weighting: Not all tokens are equally important in poetic or character-driven dialogue. Adding weight to certain tokens (e.g., rare words or named entities) could help improve diversity and focus."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
